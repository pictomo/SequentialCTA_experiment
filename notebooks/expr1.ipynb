{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from haio import (\n",
    "    HAIOClient,\n",
    "    Gemini_IO,\n",
    "    OpenAI_IO,\n",
    "    Bedrock_IO,\n",
    "    QuestionTemplate,\n",
    "    img_to_url,\n",
    ")\n",
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../modules\")\n",
    "\n",
    "from virtual_human_io import VirtualHuman_IO\n",
    "from vec_to_img import vec_to_img\n",
    "\n",
    "top_dir = \"/Users/pictomo/Repositories/SequentialCTA_experiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "labels = [\n",
    "    \"Airplane\",\n",
    "    \"Car\",\n",
    "    \"Bird\",\n",
    "    \"Cat\",\n",
    "    \"Deer\",\n",
    "    \"Dog\",\n",
    "    \"Frog\",\n",
    "    \"Horse\",\n",
    "    \"Ship\",\n",
    "    \"Truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare haio\n",
    "\n",
    "\n",
    "virtual_human_io = VirtualHuman_IO()\n",
    "gemini_io = Gemini_IO()\n",
    "openai_io = OpenAI_IO()\n",
    "llama_io = Bedrock_IO(\"us.meta.llama3-2-90b-instruct-v1:0\")\n",
    "nova_io = Bedrock_IO(\"us.amazon.nova-lite-v1:0\")\n",
    "\n",
    "haio_client = HAIOClient(\n",
    "    filepath=f\"{top_dir}/sandbox\",\n",
    "    human_io=virtual_human_io,\n",
    "    openai_io=openai_io,\n",
    "    gemini_io=gemini_io,\n",
    "    llama_io=llama_io,\n",
    "    nova_io=nova_io,\n",
    "    # # claude_io=claude_io,\n",
    ")\n",
    "\n",
    "question_template: QuestionTemplate = QuestionTemplate(\n",
    "    title=\"CIFAR-10 Image Classification\",\n",
    "    description=\"Classify the image using the CIFAR-10 dataset\",\n",
    "    question=[\n",
    "        {\"tag\": \"img\", \"src\": 0},\n",
    "        {\n",
    "            \"tag\": \"h1\",\n",
    "            \"value\": \"Choose the label that best describes the image from the options.\",\n",
    "        },\n",
    "        {\"tag\": \"p\", \"value\": \" \".join(labels)},\n",
    "    ],\n",
    "    answer={\n",
    "        \"type\": \"select\",\n",
    "        \"options\": labels,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "async def expr1(\n",
    "    execution_config: dict, task_count: int, task_phase_size: int = 1\n",
    ") -> dict:\n",
    "    result = {\"question_count\": [0], \"human_count\": [0], \"collect_count\": [0]}\n",
    "\n",
    "    asked_questions = []\n",
    "    for i in range(task_count):\n",
    "        print(\"task:\",i)\n",
    "        # print(hashlib.md5(x_train[i].tobytes()).hexdigest())\n",
    "        img_url = img_to_url(img_data=vec_to_img(x_train[i]), mime_type=\"image/png\")\n",
    "        # print(hashlib.md5(vec_to_img(x_train[i])).hexdigest())\n",
    "        data_list = [img_url]\n",
    "        asked_questions.append(\n",
    "            haio_client.ask(\n",
    "                question_template=question_template,\n",
    "                data_list=data_list,\n",
    "            )\n",
    "        )\n",
    "        if len(asked_questions) >= task_phase_size or i == task_count - 1:\n",
    "            answer_info: HAIOClient.MethodReturn = await haio_client.wait(\n",
    "                asked_questions=asked_questions, execution_config=execution_config\n",
    "            )\n",
    "            result[\"question_count\"].append(\n",
    "                result[\"question_count\"][-1] + len(asked_questions)\n",
    "            )\n",
    "            result[\"human_count\"].append(\n",
    "                result[\"human_count\"][-1] + answer_info[\"add_human_assign\"]\n",
    "            )\n",
    "            collect_count = 0\n",
    "            for j in range(len(asked_questions)):\n",
    "                if (\n",
    "                    answer_info[\"answer_list\"][j]\n",
    "                    == labels[y_train[i - len(asked_questions) + 1 + j][0]]\n",
    "                ):\n",
    "                    collect_count += 1\n",
    "            result[\"collect_count\"].append(result[\"collect_count\"][-1] + collect_count)\n",
    "            asked_questions = []\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensure_dir import ensure_dir\n",
    "\n",
    "ensure_dir(f\"{top_dir}/results/expr1\")\n",
    "\n",
    "execution_config_list = [\n",
    "    ({\"method\": \"sequential_cta_1\"}, \"cta1\"),\n",
    "    ({\"method\": \"sequential_gta_1\"}, \"gta1\"),\n",
    "    ({\"method\": \"sequential_cta_2\"}, \"cta2\"),\n",
    "    ({\"method\": \"sequential_gta_2\"}, \"gta2\"),\n",
    "    ({\"method\": \"sequential_cta_3\"}, \"cta3\"),\n",
    "    ({\"method\": \"sequential_gta_3\"}, \"gta3\"),\n",
    "]\n",
    "for task_phase_size in [1]:\n",
    "    for quality_requirement in [0.8, 0.85, 0.9, 0.925, 0.95, 0.975]:\n",
    "        for execution_config, name in execution_config_list:\n",
    "            print(name, task_phase_size, quality_requirement)\n",
    "            haio_client.del_cache_use_hist()\n",
    "            haio_client.reset_state()\n",
    "            execution_config[\"quality_requirement\"] = quality_requirement\n",
    "            if name in [\"cta2\", \"gta2\"]:\n",
    "                # execution_config[\"sample_size\"] = {0.8: 400, 0.85: 500, 0.9: 600, 0.95: 700}[quality_requirement]\n",
    "                execution_config[\"sample_size\"] = 500\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n",
    "            result = await expr1(execution_config=execution_config, task_count=10000, task_phase_size=task_phase_size)\n",
    "            with open(\n",
    "                f\"{top_dir}/results/expr1/{name}_{task_phase_size}_{quality_requirement}_{timestamp}.json\", \"w\"\n",
    "            ) as f:\n",
    "                json.dump(result, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
